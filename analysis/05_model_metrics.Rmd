---
title: "Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
#library(moderndive)
library(lme4)
library(broom.mixed)
library(lmerTest)
library(cowplot)
```
#### Read in data, get final dataset for models
Get data and put it in long form 
```{r}
pins::board_register_github(repo = "karinorman/biodivTS_data", branch = "master")

#get metadata
meta <- pins::pin_get("meta", board = "github") %>%
  select(study_id, realm, climate, habitat, protected_area, biome_map)

meta <- pins::pin_get("bt-traitfiltered", board = "github") %>%
  select(study_id, rarefyid, taxa) %>% distinct() %>%
  left_join(meta)

#get metric data
metrics <- pins::pin_get("rarefied-metrics", board = "github") %>%
  # pivot_longer(., cols = setdiff(everything(), one_of("rarefyID", "STUDY_ID", "SamplePool", "SampleN", "num_years", "duration", "startYear", "endYear", "YEAR", "cell", "rarefied", "type", "realm", "climate", "habitat", "biome_map", "taxa", "organisms", "cent_lat", "cent_long", "abundance_type", "BROAD_TYPE", "taxa_mod", "climate_mod")), names_to = "metric", values_to = "value") %>%
  rename_with(tolower, .cols = setdiff(everything(), one_of("rarefyID")))  %>%
  mutate(logvalue = log(value + 1)) %>% # create a column for log transformation that adds the absolute value integer closest to the most negative value to create all positive values
  left_join(meta, c("rarefyID" = "rarefyid"))

## Now the data that actually makes it into the model ##

#get rarefyID's that don't have enough null samples
missing_null <- bind_rows(metrics %>% 
  filter(n_missing_nulls == 1, commplete_null_samps == FALSE),
  metrics %>% filter(n_missing_nulls > 100)) %>%
  pull(rarefyID) %>%
  unique()

model_data <- metrics %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "Jaccard_next",
                       "FRic", "FEve", "FDiv", "S"),
         !rarefyID %in% missing_null) %>%
  group_by(metric) %>%
  mutate(study_id =  str_extract(rarefyID, "[^_]+")) %>%
  mutate(year_scaled = scale(year), 
         scale_center = attributes(year_scaled)$`scaled:center`, 
         scale = attributes(year_scaled)$`scaled:scale`) %>%
  ungroup() %>%
  #this study has many low species richness observations, so FD metrics weren't calculated, just drop it
  filter(study_id != 348)

pins::pin(model_data, board = "github")
```
Add human footprint data
```{r}
# hfp_data <- pins::pin_get("hfp-data", board = "github")
# 
# model_data_hfp <- model_data %>% 
#   #dplyr::select(rarefyID, year) %>% 
#   #distinct() %>%
#   mutate(hfp_year = case_when(
#     year < 2001 ~ 1993,
#     TRUE ~ 2009
#   ), 
#   hfp_rarefyID = str_replace_all(rarefyID, pattern = "_bird", ""), 
#   hfp_rarefyID = str_replace_all(hfp_rarefyID, pattern = "_mamm", "")) %>%
#   left_join(hfp_data %>% dplyr::select(-STUDY_ID) %>% mutate(year = as.numeric(year)), by = c("hfp_year" = "year", "hfp_rarefyID" = "rarefyID")) %>%
#   dplyr::select(-hfp_year)

```

####Data exploration

Visualize number of years for each timeseries
```{r}
hist_numYears <- metrics %>%
  select(year, rarefyID) %>% 
  distinct() %>% 
  count(rarefyID, name = "num_years") %>% 
  ggplot() +
  geom_histogram(aes(x = num_years),
                 binwidth = 2) +
  scale_x_continuous(name = 'Number of years sampled',
                     breaks = c(2,4,8,16,32,48,64,96)) +
  #scale_y_continuous(breaks = c(0,2500,5000,7500,10000,12500, 15000, 17500, 20000,22500)) +
  labs(tag = 'B',
       y = 'Number of cells') +
  theme_bw() +
  theme(panel.grid.minor.x = element_blank())
```

Visualize distributions of response
```{r}
metrics %>%
  filter(metric %in% c("FRic", "FEve", "FDiv", "FDis", "S", "Jaccard_hind")) %>%
  ggplot() +
  geom_histogram(aes(x = logvalue),
                 bins = 60) +
  facet_wrap(~metric, scales = "free") +
  labs(title = "Distribution of Log values")

metrics %>%
  filter(metric %in% c("FRic", "FEve", "FDiv", "FDis", "S", "SES_FDis", "SES_FDiv", "SES_FEve", "SES_FRic", "Jaccard_hind")) %>%
  ggplot() +
  geom_histogram(aes(x = value),
                 bins = 60) +
  facet_wrap(~metric, scales = "free") +
  labs(title = "Distribution of raw values")
```

####Fit GLMs to overall patterns and data broken down by groups

Convergence problems!! See here:
https://joshua-nugent.github.io/allFit/
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
https://biologyforfun.wordpress.com/2018/04/09/help-i-have-convergence-warnings/

Model checks:
https://debruine.github.io/posts/normality/
performance::check_model()

Function approach to model
```{r}
get_model <- function(metric_name, formula, model_id, data, ...){
  print(c(metric_name, model_id))
  qlmer <- quietly(lmer)
  
  fit <- data %>%
    filter(metric == metric_name) %>%
    mutate(year_scaled = scale(year)) %>%
    qlmer(formula = formula, data = ., ...)
  
  tidy(fit$result) %>%
   mutate(metric = metric_name, model = list(fit$result), model_id = model_id, warning = ifelse(length(fit$warnings) == 0, NA, fit$warnings))
}

#get_model(data = model_data, metric_name = "SES_FRic", "value ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|climate)", model_id = "base")
```

Create dataframe of models to fit
```{r}
raw_value_mods <- tibble(metric_name = c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base"), 
                         base = "value ~ year_scaled + (year_scaled|study_id/rarefyID)",
                         taxa = "value ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|taxa)",
                         realm = "value ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|realm)",
                         climate = "value ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|climate)") %>%
  pivot_longer(cols = c(base, taxa, realm, climate), names_to = "model_id", values_to = "formula")

log_value_mods <- tibble(metric_name = c("S"), 
                         base = "logvalue ~ year_scaled + (year_scaled|study_id/rarefyID)",
                         taxa = "logvalue ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|taxa)",
                         realm = "logvalue ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|realm)",
                         climate = "logvalue ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|climate)") %>%
  pivot_longer(cols = c(base, taxa, realm, climate), names_to = "model_id", values_to = "formula")

mods <- bind_rows(raw_value_mods, log_value_mods) %>% 
  select(metric_name, formula, model_id)
```

Fit models
```{r}
#Fit models with base settings
mod_results <- pmap_dfr(mods, get_model, data = model_data)

#get the models that had convergence warnings
bad_models <- mod_results %>%
  select(metric, model_id, warning) %>% 
  filter(!is.na(warning)) %>% 
  distinct() %>%
  left_join(mods, by = c("metric" = "metric_name", "model_id")) 

#Turn of REML for these models 
bad_mod_results <- pmap_dfr(bad_models %>% select(-warning), get_model, data = model_data, REML = FALSE)

#One model still won't converge
bad_models2 <- bad_mod_results %>%
  select(metric, model_id, warning) %>% 
  filter(!is.na(warning)) %>% 
  distinct() %>%
  left_join(mods, by = c("metric" = "metric_name", "model_id")) 

#Fit with a different algorithm
bad_mod_results2 <- pmap_dfr(bad_models2 %>% select(-warning), get_model, data = model_data, control = lmerControl(optimizer = "bobyqa"))

metric_model_table <- bind_rows(mod_results %>% filter(is.na(warning)), 
          bad_mod_results %>% filter(is.na(warning)),
          bad_mod_results2 %>% filter(is.na(warning))) 

usethis::use_data(metric_model_table)
pins::pin(metric_model_table, board = "github")
```


```{r}
# SES_rand_slope <- model_data %>%
#   filter(metric %in%  c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_next")) %>%
#   group_nest(metric) %>%
#   mutate(#year_center = map(data, ~scale(.x$year)),
#          model = map(data, ~lmer(value ~ year_scaled + (year_scaled|study_id/rarefyID), 
#                                  data = .x)),
#            # null_model = map(data, ~lmer(value ~ (year_scaled|study_id/rarefyID), 
#            #                       data = .x)),
#            # test = map2(model, null_model, anova),
#            # test_res = map(test, tidy),
#            coef = map(model, tidy),
#            ) %>% 
#   select(metric, model, coef) %>%
#   unnest(cols = c(coef)) %>%
#   filter(term == "year_scaled") %>%
#   select(-c(effect, group, term, statistic))
# 
# #check that they all used the same number of observations
# map(SES_rand_slope$model, nobs)
# 
# #these two metrics are cranky and want their own year scaling to converge
# 
# #Jaccard Base
# jacc_base_mod <-  model_data %>%
#   filter(metric == ("Jaccard_base")) %>%
#   mutate(year_scaled = scale(year)) %>%
#   group_nest(metric) %>%
#   mutate(model = map(data, ~lmer(value ~ year_scaled + (year_scaled|study_id/rarefyID), 
#                                  data = .x)),
#            coef = map(model, tidy),
#            ) %>% 
#   select(metric, model, coef) %>%
#   unnest(cols = c(coef)) %>%
#   filter(term == "year_scaled") %>%
#   select(-c(effect, group, term, statistic))
# 
# # S model
# s_mod <- model_data %>%
#   filter(metric %in%  c("S")) %>%
#   #it wants its own scaling to converge for some reason
#   mutate(year_scaled = scale(year)) %>%
#   group_nest(metric) %>%
#   mutate(model = map(data, ~lmer(logvalue ~ year_scaled + (year_scaled|study_id/rarefyID), 
#                                  data = .x, REML = TRUE)),
#            coef = map(model, tidy)
#            ) %>% 
#   select(metric, model, coef) %>%
#   unnest(cols = c(coef)) %>%
#   filter(term == "year_scaled") %>%
#   select(-c(effect, group, term, statistic))
# 
# metric_model_table <- bind_rows(SES_rand_slope, s_mod, jacc_base_mod)
# 
# #save coefficients and models
# usethis::use_data(metric_model_table)
# pins::pin(metric_model_table, board = "github")
# ```
# Taxa model
# ```{r}
# taxa_rand_slope <- model_data %>%
#   filter(metric %in%  c("SES_FRic", "SES_FEve", "SES_FDiv")) %>%
#   group_nest(metric) %>%
#   mutate(#year_center = map(data, ~scale(.x$year)),
#          model = map(data, ~lmer(value ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|taxa), 
#                                  data = .x)),
#            # null_model = map(data, ~lmer(value ~ (year_scaled|study_id/rarefyID), 
#            #                       data = .x)),
#            # test = map2(model, null_model, anova),
#            # test_res = map(test, tidy),
#            coef = map(model, tidy),
#            ) %>% 
#   select(metric, model, coef) %>%
#   unnest(cols = c(coef))
# 
# #Jaccard Base
# jacc_taxa_base_mod <-  model_data %>%
#   filter(metric == ("Jaccard_base")) %>%
#   mutate(year_scaled = scale(year)) %>%
#   group_nest(metric) %>%
#   mutate(model = map(data, ~lmer(value ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|taxa), 
#                                  data = .x)),
#            coef = map(model, tidy),
#            ) %>% 
#   select(metric, model, coef) %>%
#   unnest(cols = c(coef)) %>%
#   filter(term == "year_scaled") %>%
#   select(-c(effect, group, term, statistic))
# 
#  s_taxa_mod <- model_data %>%
#   filter(metric %in%  c("S")) %>%
#   #it wants its own scaling to converge for some reason
#   mutate(year_scaled = scale(year)) %>%
#   group_nest(metric) %>%
#   mutate(model = map(data, ~lmer(logvalue ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|taxa), 
#                                  data = .x, REML = TRUE)),
#            coef = map(model, tidy)
#            ) %>% 
#   select(metric, model, coef) %>%
#   unnest(cols = c(coef)) %>%
#   filter(term == "year_scaled") %>%
#   select(-c(effect, group, term, statistic))
# 
# fric_taxa_mod <- model_data %>%
#   filter(metric %in%  c("SES_FRic")) %>%
#   #it wants its own scaling to converge for some reason
#   mutate(year_scaled = scale(year)) %>%
#   group_nest(metric) %>%
#   mutate(model = map(data, ~lmer(logvalue ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|taxa), 
#                                  data = .x, REML = TRUE)),
#            coef = map(model, tidy)
#            ) %>% 
#   select(metric, model, coef) %>%
#   unnest(cols = c(coef)) %>%
#   filter(term == "year_scaled") %>%
#   select(-c(effect, group, term, statistic))
# 
# taxa_model_table <- bind_rows(taxa_rand_slope, jacc_taxa_base_mod, s_taxa_mod, fric_taxa_mod)
```

#### Process Model Output

Get study level slope estimates
```{r}
get_study_slopes <- function(metric, model, model_id){
  
  filter_name <- ifelse(model_id == "base", "study_id", model_id)
  
  year_scaled_coef <- tidy(model) %>%
    filter(term == "year_scaled") 
  
  year_scaled_est <- pull(year_scaled_coef, estimate) 
  
  year_scaled_var <- year_scaled_coef %>% 
    mutate(var = std.error*std.error) %>%
    pull(var)
  
  study_ests <- broom.mixed::tidy(model, effects="ran_vals") %>%
    filter(group == filter_name, term == "year_scaled") %>% 
    select(-c(effect, group, term)) %>%
    #rename({{ model_id }} := level, cond.std.error = std.error, cond.estimate = estimate) %>%
    rename(cond.std.error = std.error, cond.estimate = estimate) %>%
    mutate(estimate = cond.estimate + year_scaled_est,
      cond.var = cond.std.error*cond.std.error, 
           var = cond.var + year_scaled_var,
           std.error = sqrt(var),
           upr.ci = estimate + (2*std.error),
           lwr.ci = estimate - (2*std.error),
           sig = case_when(
             lwr.ci < 0 & upr.ci > 0 ~ FALSE,
             TRUE ~ TRUE
           ),
      metric = metric,
      model_id = model_id)
}

model_df <- metric_model_table %>%
  select(metric, model, model_id) %>%
  group_by(metric, model_id) %>% 
  slice_head()

#get study level slopes for base, and levels for categorical random effect in non-base models
re_slopes <- pmap_dfr(model_df, get_study_slopes)

#get only study-level slopes for the base models
study_slopes <- re_slopes %>% 
  filter(model_id == "base") %>%
  rename(study_id = level)

study_slopes_wide <- study_slopes %>%
  select(study_id, metric, estimate) %>%
  pivot_wider(names_from = "metric", values_from = "estimate")
```

Summaries of study slopes
```{r}
#First - how many studies had a significant trend for each metric? 
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S")) %>% 
  group_by(metric) %>% 
  summarise(n_study_id = n_distinct(study_id)) %>%
  mutate(percent = n_study_id/53) 

#And which studies were they?
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S")) %>% 
  select(study_id, metric) %>%
  distinct()

#Which were significant for multiple metrics?
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S")) %>% 
  group_by(study_id) %>%
  filter(n() > 1) %>%
  select(study_id, metric)
```

```{r}
# #And how many were significant for all but Jaccard?
# study_slopes %>% 
#   filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "S")) %>% 
#   group_by(study_id) %>% filter(sum(sig) == 4) %>% pull(study_id) %>% 
#   n_distinct()
# 
# #Breakdown of relationship between functional richness and species richness
# s_sig <- study_slopes %>% filter(metric == "S", sig == TRUE) %>% pull(study_id) %>% unique()
# s_sig_not_fric <- study_slopes %>% 
#   filter(study_id %in% s_sig, metric == "FRic", sig == FALSE) %>% 
#   pull(study_id) %>%
#   unique()
# 
# both_sig <- study_slopes %>% 
#   filter(study_id %in% s_sig, metric == "FRic", sig == TRUE) %>%
#   pull(study_id)
# 
# both_pos
# fric_pos
# s_pos_fric_neg <- study_slopes %>%
#   filter(study_id %in% both_sig) %>% 
#   group_by(study_id) %>%
#   filter(sum(sign(estimate)) == 0) 

```

#### Analizing slopes
Is slope a function of timeseries characteristics?
```{r}
library(multcomp)

study_slope_data <- study_slopes %>%
  dplyr::select(study_id, metric, estimate) %>%
  left_join(meta %>% 
              dplyr::select(-rarefyid) %>% 
              distinct() %>%
              mutate(study_id = as.character(study_id))) %>%
  left_join(model_data %>% dplyr::select(study_id, startyear, duration) %>% distinct())


duration_slope <- study_slope_data %>%
  group_nest(metric) %>%
  mutate(model = map(data, ~glm(estimate ~ duration, 
                                 data = .x)),
           coef = map(model, tidy),
           ) %>% 
  dplyr::select(metric, coef) %>%
  unnest(cols = c(coef)) %>%
  mutate(covariate = "duration")

startyear_slope <- study_slope_data %>%
  group_nest(metric) %>%
  mutate(model = map(data, ~glm(estimate ~ startyear, 
                                 data = .x)),
           coef = map(model, tidy),
           ) %>% 
  dplyr::select(metric, coef) %>%
  unnest(cols = c(coef)) %>%
  mutate(covariate = "startyear")

#All model estimates in one dataframe
slope_models <- bind_rows(duration_slope, startyear_slope)

# Which predictor variables were significant?
slope_models %>% filter(term != "(Intercept)", p.value < 0.05) %>% View()
```

Pairwise correlation analysis
```{r}
library(psych)
#slope_corr <- corr.test(slopes_wide %>% ungroup() %>% select(starts_with("SES"), "S", "Jaccard_base"))

slope_corr_bootstrap <- corCi(slopes_wide %>% ungroup() %>% select(starts_with("SES"), "S", "Jaccard_base"))
```

Clustering 
```{r}
library(clValid)
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)

scale_slopes <- slopes_wide %>%  
  drop_na() %>%
  select(study_id, starts_with("SES"), S, Jaccard_base) %>%
  column_to_rownames("study_id") %>%
  mutate(across(.fns = scale2)) %>%
  as.matrix()

clmethods <- c("hierarchical","kmeans","pam")
intern <- clValid(scale_slopes, nClust = 2:6, clMethods = clmethods, validation = "internal")
stab <- clValid(scale_slopes, nClust = 2:6, clMethods = clmethods, validation = "stability")

summary(intern)
optimalScores(stab)

#get the hierarchical clustering object
clust <- intern@clusterObjs$hierarchical
cat5 <- cutree(clust, k = 5)
cat3 <- cutree(clust, k = 3)


slopes_clust <- slopes_wide %>% 
  ungroup() %>%
  left_join(as.data.frame(cat3) %>%
  rownames_to_column("study_id")) %>%
  left_join(as.data.frame(cat5) %>%
  rownames_to_column("study_id"))
```

```{r}
slopes_clust %>% 
  gatherpairs( "SES_FDiv", "SES_FEve", "SES_FRic", "S", "Jaccard_base") %>% {
  ggplot(., aes(x = .xvalue, y = .yvalue, color = as.factor(cat5))) +
      geom_point() + 
      #geom_smooth(method = 'lm') +
      facet_wrap(.xkey ~ .ykey, ncol = length(unique(.$.ykey)), scales = 'free', labeller = label_both) +
      scale_color_brewer(type = 'qual')
  }
```

####Figures

Pairwise plots of study-level slopes
```{r}
#pairwise plots using GGally
ggpairs(slopes_wide %>% 
          select(-c("study_id", "FDiv", "FEve", "FRic")))

#pairwise plots using GGPlot
gatherpairs <- function(data, ..., 
                        xkey = '.xkey', xvalue = '.xvalue',
                        ykey = '.ykey', yvalue = '.yvalue',
                        na.rm = FALSE, convert = FALSE, factor_key = FALSE) {
  vars <- quos(...)
  xkey <- enquo(xkey)
  xvalue <- enquo(xvalue)
  ykey <- enquo(ykey)
  yvalue <- enquo(yvalue)

  data %>% {
    cbind(gather(., key = !!xkey, value = !!xvalue, !!!vars,
                 na.rm = na.rm, convert = convert, factor_key = factor_key),
          select(., !!!vars)) 
  } %>% gather(., key = !!ykey, value = !!yvalue, !!!vars,
               na.rm = na.rm, convert = convert, factor_key = factor_key)
}

slopes_wide %>% 
  gatherpairs( "SES_FDiv", "SES_FEve", "SES_FRic", "S") %>% {
  ggplot(., aes(x = .xvalue, y = .yvalue)) +
      geom_point() + 
      #geom_smooth(method = 'lm') +
      facet_wrap(.xkey ~ .ykey, ncol = length(unique(.$.ykey)), scales = 'free', labeller = label_both) +
      scale_color_brewer(type = 'qual')
  }

slopes_wide %>%
  select(-c("FDiv", "FEve", "FRic")) %>%
  pivot_longer(-one_of("study_id", "S"), names_to = "metric") %>%
  ggplot(aes(x = S, y = value)) +
  geom_point() +
  facet_wrap(~metric) +
  xlim(-1.3, 1.3) +
  ylim(-0.6, 0.6) +
    theme_classic() +
    geom_hline(yintercept = 0) +
    geom_vline(xintercept = 0) + 
  ylab("Metric Slope") +
  xlab("Richness Slope")

slopes_wide %>%
  select(-c("FDiv", "FEve", "FRic")) %>%
  pivot_longer(-one_of("study_id", "SES_FRic"), names_to = "metric") %>%
  ggplot(aes(x = SES_FRic, y = value)) +
  geom_point() +
  facet_wrap(~metric) +
  xlim(-.25, .25) +
  ylim(-0.6, 0.6) +
    theme_classic() +
    geom_hline(yintercept = 0) +
    geom_vline(xintercept = 0) + 
  ylab("Metric Slope") +
  xlab("Functional Richness Slope")
```

```{r}
library(cowplot)
library(RColorBrewer)

plot_metric <- function(metric_name, ylabel, yval, xlabel, data, model_coef, color_list){

  if(is.na(xlabel)) xlabel <- NULL
  
  data <- data %>%
    filter(metric == metric_name, !is.na(value), !is.infinite(value))

  model_coef <- model_coef %>%
    filter(metric == metric_name) %>%
    select(term, estimate)
  
  intercept <- model_coef %>% filter(term == "(Intercept)") %>% pull(estimate)
  slope <- model_coef %>% filter(term == "year_scaled") %>% pull(estimate)
  
  pred <- data %>%
    select(year_scaled) %>%
    distinct() %>%
    mutate(pred = intercept + year_scaled * slope)

  trend_plot <- data %>%
    left_join(pred, by = "year_scaled") %>%
    #left_join(metadata %>% select(study_id, climate)) %>%
    ggplot(aes(x = year, y = !!sym(yval))) +
    # geom_smooth(aes(color = climate, group = rarefyID), method = "glm", se = FALSE) +
    # geom_point(aes(color = climate, group = rarefyID)) +
    geom_point(aes(group = rarefyID) ,color = "grey", size = 0.25) +
    geom_smooth(aes(color = climate, group = study_id), method = "glm", se = FALSE, size = 0.7) +
    #geom_smooth(color = "black", method = "glm", se = FALSE) +
    geom_line(mapping = aes(y = pred)) +
    theme_classic() +
    theme(axis.title = element_text(size=7), legend.position = "none") +
    ylab(ylabel) +
    xlab(xlabel) +
    labs(color = "Climate") +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 6)) +
    scale_colour_manual(values = color_list, drop = FALSE)
    
    #scale_color_manual(values = c("#32a251", 
               # "#ff7f0f", "#39737c", "#b85a0d", "#ffd94a"))
  
  ggsave(paste0(here::here("figures"), "/",metric_name, "_trend.png"), trend_plot)
  return(trend_plot)
}

model_coef <- metric_model_table %>%
  select(metric, model) %>%
   mutate(coef = map(model, tidy)) %>% 
  select(-model) %>% 
  unnest(cols = c(coef))

pal <- brewer.pal(n = 5, name = "Dark2")
group_colors <- c("Global" = pal[1], "Polar/Temperate" = pal[2], "Temperate/Tropical" = pal[3], "Tropical" = pal[4], "Temperate" = pal[5], "Overall Mean" = "#000000")

plot_map <- tibble(metric_name = c("S", "Jaccard_base", "SES_FRic", "SES_FDiv", "SES_FEve"), 
           ylabel = c("log(S)", "Jaccard", "Functional Richness SES", "Functional Divergence SES", "Functional Evenness SES"),
           #ylabel = c("log(S)", "Jaccard", "FRic SES", "FDiv SES", "FEve SES"),
           yval = c("logvalue", "value", "value", "value", "value"),
           xlabel = c(NA, NA, NA, "year", "year"))
m_plots <- pmap(plot_map, plot_metric, data = model_data, model_coef = model_coef, color_list = group_colors)

plot_join <- plot_grid(plotlist=m_plots, labels = "AUTO", nrow = 3, align = 'vh',
                       hjust = -1, axis = "l", scale = 0.9)

leg_plot <- model_data %>%
  bind_rows(data.frame(climate = c("Overall Mean", "Overall Mean"), year = c(2019, 2020), value = c(1, 1))) %>%
  ggplot(aes(x = year, y = value)) +
  geom_point(color = "grey", size = 0.50) +
  geom_smooth(aes(color = climate, group = study_id), method = "glm", se = FALSE, size = 0.7) +
  theme_classic() +
  theme(axis.title = element_text(size=7)) +
  scale_colour_manual(values = group_colors, drop = FALSE)

# extract the legend from one of the plots
legend <- get_legend(leg_plot)

# add the legend to the row we made earlier. Give it one-third of 
# the width of one plot (via rel_widths).
#plot_join + draw_grob(legend,  2/3.3, -0.3, .3/3.3, 1, scale = 0.6)
plot_join + draw_grob(legend,  2/3.3, -0.3,.3/3.3, 1, scale = 0.01)

ggsave2(here::here("figures", "3met_long.jpeg"))
```
