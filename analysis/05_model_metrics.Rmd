---
title: "Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lme4)
library(broom.mixed)
library(lmerTest)
library(emmeans)
```
#### Read in data, get final dataset for models
Get data and put it in long form 
```{r}
pins::board_register_github(repo = "karinorman/biodivTS_data", branch = "master")

#get metadata
meta <- pins::pin_get("meta", board = "github") %>%
  select(study_id, realm, climate, habitat, protected_area, biome_map)

meta <- pins::pin_get("bt-traitfiltered", board = "github") %>%
  select(study_id, rarefyid, taxa) %>% distinct() %>%
  left_join(meta)

#get metric data
metrics <- pins::pin_get("rarefied-metrics", board = "github") %>%
  # pivot_longer(., cols = setdiff(everything(), one_of("rarefyID", "STUDY_ID", "SamplePool", "SampleN", "num_years", "duration", "startYear", "endYear", "YEAR", "cell", "rarefied", "type", "realm", "climate", "habitat", "biome_map", "taxa", "organisms", "cent_lat", "cent_long", "abundance_type", "BROAD_TYPE", "taxa_mod", "climate_mod")), names_to = "metric", values_to = "value") %>%
  rename_with(tolower, .cols = setdiff(everything(), one_of("rarefyID")))  %>%
  mutate(logvalue = log(value + 1)) %>% # create a column for log transformation that adds the absolute value integer closest to the most negative value to create all positive values
  left_join(meta, c("rarefyID" = "rarefyid"))

## Now the data that actually makes it into the model ##

#get rarefyID's that don't have enough null samples
missing_null <- bind_rows(metrics %>% 
  filter(n_missing_nulls == 1, commplete_null_samps == FALSE),
  metrics %>% filter(n_missing_nulls > 100)) %>%
  pull(rarefyID) %>%
  unique()

model_data <- metrics %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "Jaccard_next",
                       "FRic", "FEve", "FDiv", "S","CWM_bodymass_value","CWM_diet_inv", 
                       "CWM_diet_scav", "CWM_diet_vfish", "CWM_diet_vunk", "CWM_forstrat_ground", 
                       "CWM_forstrat_wataroundsurf", "CWM_forstrat_watbelowsurf", "CWM_diet_fruit", 
                       "CWM_diet_planto", "CWM_diet_seed", "CWM_diet_vend", "CWM_forstrat_understory", 
                       "CWM_diet_vect", "CWM_diet_nect", "CWM_forstrat_aerial", "CWM_forstrat_canopy", 
                       "CWM_forstrat_midhigh", "CWM_age_at_maturity_max_y", "CWM_age_at_maturity_min_y", 
                       "CWM_body_size_mm", "CWM_litter_size_max_n", "CWM_litter_size_min_n", 
                       "CWM_longevity_max_y", "CWM_offspring_size_max_mm", "CWM_offspring_size_min_mm"),
         !rarefyID %in% missing_null) %>%
  group_by(metric) %>%
  mutate(study_id =  str_extract(rarefyID, "[^_]+")) %>%
  mutate(year_scaled = scale(year), 
         scale_center = attributes(year_scaled)$`scaled:center`, 
         scale = attributes(year_scaled)$`scaled:scale`) %>%
  ungroup() %>%
  #this study has many low species richness observations, so FD metrics weren't calculated, just drop it
  filter(study_id != 348)

pins::pin(model_data, board = "github")
```

Write out file with all necessary metadata for the supplement.
```{r}
meta %>% 
  filter(study_id %in% model_data$study_id) %>% 
  select(-c(link_id, date_study_added, sample_desc_name)) %>% 
  write_csv(here::here("paper", "study_metadata.csv"))
```


Option to add human footprint data
```{r}
# hfp_data <- pins::pin_get("hfp-data", board = "github")
# 
# model_data_hfp <- model_data %>% 
#   #dplyr::select(rarefyID, year) %>% 
#   #distinct() %>%
#   mutate(hfp_year = case_when(
#     year < 2001 ~ 1993,
#     TRUE ~ 2009
#   ), 
#   hfp_rarefyID = str_replace_all(rarefyID, pattern = "_bird", ""), 
#   hfp_rarefyID = str_replace_all(hfp_rarefyID, pattern = "_mamm", "")) %>%
#   left_join(hfp_data %>% dplyr::select(-STUDY_ID) %>% mutate(year = as.numeric(year)), by = c("hfp_year" = "year", "hfp_rarefyID" = "rarefyID")) %>%
#   dplyr::select(-hfp_year)

```

####Data exploration

Visualize number of years for each timeseries
```{r}
hist_numYears <- metrics %>%
  select(year, rarefyID) %>% 
  distinct() %>% 
  count(rarefyID, name = "num_years") %>% 
  ggplot() +
  geom_histogram(aes(x = num_years),
                 binwidth = 2) +
  scale_x_continuous(name = 'Number of years sampled',
                     breaks = c(2,4,8,16,32,48,64,96)) +
  #scale_y_continuous(breaks = c(0,2500,5000,7500,10000,12500, 15000, 17500, 20000,22500)) +
  labs(tag = 'B',
       y = 'Number of cells') +
  theme_bw() +
  theme(panel.grid.minor.x = element_blank())
```

Visualize distributions of response
```{r}
metrics %>%
  filter(metric %in% c("FRic", "FEve", "FDiv", "FDis", "S", "Jaccard_hind")) %>%
  ggplot() +
  geom_histogram(aes(x = logvalue),
                 bins = 60) +
  facet_wrap(~metric, scales = "free") +
  labs(title = "Distribution of Log values")

metrics %>%
  filter(metric %in% c("FRic", "FEve", "FDiv", "FDis", "S", "SES_FDis", "SES_FDiv", "SES_FEve", "SES_FRic", "Jaccard_hind")) %>%
  ggplot() +
  geom_histogram(aes(x = value),
                 bins = 60) +
  facet_wrap(~metric, scales = "free") +
  labs(title = "Distribution of raw values")
```

####Fit GLMs to overall patterns and data broken down by groups

Convergence problems! See here:
https://joshua-nugent.github.io/allFit/
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
https://biologyforfun.wordpress.com/2018/04/09/help-i-have-convergence-warnings/

Model checks:
https://debruine.github.io/posts/normality/
performance::check_model()

Function approach to model
```{r}
get_model <- function(metric_name, formula, model_id, data, ...){
  print(c(metric_name, model_id))
  qlmer <- quietly(lmer)
  
  fit_data <- data %>%
    filter(metric == metric_name) %>%
    mutate(year_scaled = scale(year),
           duration_scaled = scale(duration, scale = FALSE),
           startyear_scaled = scale(startyear, scale = FALSE),
           taxa = as.factor(taxa),
           realm = as.factor(realm),
           climate = as.factor(climate))
  
  if(n_distinct(fit_data$rarefyID) < 2){
    return(tibble())
  }
  
  if(!model_id %in% c("base", "base_dur", "base_srt")){
    if(fit_data %>% pull(model_id) %>% n_distinct() >1) {
      
      fit <- qlmer(formula = formula, data = fit_data, ...)
      
      slopes <- get_fixed_slopes(metric = metric_name, model = fit$result, model_id = model_id, model_data = fit_data) 
      
      group_slopes <- as_tibble(slopes$emtrends) %>%
        mutate(effect = "group_slope", group = model_id) %>%
        rename(std.error = SE, estimate = year_scaled.trend, term = model_id)
      
      slope_constrasts <- as_tibble(slopes$contrasts) %>%
        mutate(effect = "contrast", group = model_id) %>%
        rename(std.error = SE, term = contrast, statistic = t.ratio)
      
      df <- tidy(fit$result) %>% 
        bind_rows(group_slopes, slope_constrasts) %>%
        mutate(metric = metric_name, model = list(fit$result), model_id = model_id,
               n_ts = n_distinct(fit_data$rarefyID),
               warning = ifelse(length(fit$warnings) == 0, NA, fit$warnings))
    }else{
      return(tibble())
    }
  }else{
    
    fit <- qlmer(formula = formula, data = fit_data, ...)
    
    tidy(fit$result) %>%
      mutate(metric = metric_name, model = list(fit$result), model_id = model_id, 
             n_ts = n_distinct(fit_data$rarefyID),
             warning = ifelse(length(fit$warnings) == 0, NA, fit$warnings))
  }
}

get_fixed_slopes <- function(metric, model, model_id, model_data){
  formula <- paste("pairwise", "~", model_id)
  fit_trends <- emtrends(model, specs = as.formula(formula), var="year_scaled",  mode = "satterth", lmerTest.limit = 20105, data = model_data)
  
  return(fit_trends)
}
#get_model(data = model_data, metric_name = "SES_FRic", "value ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|climate)", model_id = "base")
```

Create dataframe of models to fit
```{r}
metric_names <- unique(model_data$metric)
raw_value_mods <- tibble(metrimod_resultsc_name = metric_names[metric_names != "S"], 
                         base = "value ~ year_scaled + (year_scaled|study_id/rarefyID)",
                         taxa = "value ~ year_scaled * taxa + (year_scaled|study_id/rarefyID)",
                         realm = "value ~ year_scaled * realm + (year_scaled|study_id/rarefyID)",
                         climate = "value ~ year_scaled * climate + (year_scaled|study_id/rarefyID)") %>%
  pivot_longer(cols = c(base, taxa, realm, climate), names_to = "model_id", values_to = "formula")

log_value_mods <- tibble(metric_name = c("S"), 
                         base = "logvalue ~ year_scaled + (year_scaled|study_id/rarefyID)",
                         taxa = "logvalue ~ year_scaled * taxa + (year_scaled|study_id/rarefyID)",
                         realm = "logvalue ~ year_scaled * realm + (year_scaled|study_id/rarefyID)",
                         climate = "logvalue ~ year_scaled * climate + (year_scaled|study_id/rarefyID)") %>%
  pivot_longer(cols = c(base, taxa, realm, climate), names_to = "model_id", values_to = "formula")

mods <- bind_rows(raw_value_mods, log_value_mods) %>% 
  select(metric_name, formula, model_id)
```

Fit models
```{r}
#Fit models with base settings
mod_results <- pmap_dfr(mods, get_model, data = model_data)

#get the models that had convergence warnings
bad_models <- mod_results %>%
  select(metric, model_id, warning) %>% 
  filter(!is.na(warning)) %>% 
  distinct() %>%
  left_join(mods, by = c("metric" = "metric_name", "model_id")) 

#Turn off REML for these models, and they fit! 
bad_mod_results <- pmap_dfr(bad_models %>% select(-warning), get_model, data = model_data, REML = FALSE)

metric_model_table <- bind_rows(mod_results %>% filter(is.na(warning)), 
          bad_mod_results %>% filter(is.na(warning))) %>%
  mutate(significant = case_when(
    p.value > 0.05 | lower.CL < 0 & upper.CL > 0 ~ FALSE,
    !is.na(p.value) | !is.na(lower.CL) ~ TRUE,
    TRUE ~ NA
  ))

usethis::use_data(metric_model_table)
pins::pin(metric_model_table, board = "github")
```

Write out table of model estimates for manuscript
```{r}
metric_model_table %>% 
  filter(model_id == "base", metric %in% c("S", "Jaccard_base", "SES_FRic", "SES_FEve", "SES_FDiv")) %>% 
  select(-c(model, model_id, warning, statistic, df)) %>% 
  write_csv(here::here("figures", "man_model_table.csv"))
```

Models with interactions
```{r}
# int_raw_value_mods <- tibble(metric_name = c("SES_FRic", "SES_FEve", "SES_FDiv", "FRic", "FEve", "FDiv", "Jaccard_base"), 
#                          base_dur = "value ~ year_scaled + duration_scaled*year_scaled + (year_scaled|study_id/rarefyID)",
#                          base_srt = "value ~ year_scaled + startyear_scaled*year_scaled + (year_scaled|study_id/rarefyID)") %>%
#   pivot_longer(cols = c(base_dur, taxa_dur, realm_dur, climate_dur, base_srt, taxa_srt, realm_srt, climate_srt), 
#                names_to = "model_id", values_to = "formula")
# 
# int_log_value_mods <- tibble(metric_name = c("S"),
#                          base_dur = "logvalue ~ year_scaled + duration_scaled*year_scaled + (year_scaled|study_id/rarefyID)",
#                          base_srt = "logvalue ~ year_scaled + startyear_scaled*year_scaled + (year_scaled|study_id/rarefyID)") %>%
#   pivot_longer(cols = c(base_dur, taxa_dur, realm_dur, climate_dur, base_srt, taxa_srt, realm_srt, climate_srt), 
#                names_to = "model_id", values_to = "formula")
# 
# 
# # mods <- bind_rows(raw_value_mods, log_value_mods) %>% 
# #   select(metric_name, formula, model_id)
# 
# #Fit models with base settings
# int_mod_results <- pmap_dfr(bind_rows(int_raw_value_mods, int_log_value_mods), get_model, data = model_data)
# 
# #get the models that had convergence warnings
# bad_models <- int_mod_results %>%
#   select(metric, model_id, warning) %>% 
#   filter(!is.na(warning)) %>% 
#   distinct() %>%
#   left_join(int_raw_value_mods, by = c("metric" = "metric_name", "model_id")) 
```


#### Process Model Output

Get study level slope estimates
```{r}
get_study_slopes <- function(metric, model, model_id){
  
  filter_name <- ifelse(model_id == "base", "study_id", model_id)
  
  #get the statistics for the year variable
  year_scaled_coef <- tidy(model) %>%
    filter(term == "year_scaled") 
  
  #get the year estimate
  year_scaled_est <- pull(year_scaled_coef, estimate) 
  
  #get year variation
  year_scaled_var <- year_scaled_coef %>% 
    mutate(var = std.error*std.error) %>%
    pull(var)
  
  #get study level conditional estimates and add to over all estimates
  study_ests <- broom.mixed::tidy(model, effects="ran_vals") %>%
    filter(group == filter_name, term == "year_scaled") %>% 
    select(-c(effect, group, term)) %>%
    rename(cond.std.error = std.error, cond.estimate = estimate) %>%
    mutate(estimate = cond.estimate + year_scaled_est,
      cond.var = cond.std.error*cond.std.error, 
           var = cond.var + year_scaled_var,
           std.error = sqrt(var),
           upr.ci = estimate + (2*std.error),
           lwr.ci = estimate - (2*std.error),
           sig = case_when(
             lwr.ci < 0 & upr.ci > 0 ~ FALSE,
             TRUE ~ TRUE
           ),
      metric = metric,
      model_id = model_id)
}

model_df <- metric_model_table %>%
  filter(model_id == "base") %>%
  select(metric, model, model_id) %>%
  group_by(metric, model_id) %>% 
  slice_head()

#get study level slopes for base, and levels for categorical random effect in non-base models
re_slopes <- pmap_dfr(model_df, get_study_slopes)
pins::pin(re_slopes, board = "github")

#get only study-level slopes for the base models
study_slopes <- re_slopes %>% 
  filter(model_id == "base") %>%
  rename(study_id = level)

# study_slopes_wide <- study_slopes %>%
#   select(study_id, metric, estimate) %>%
#   pivot_wider(names_from = "metric", values_from = "estimate")
```

Summaries of study slopes
```{r}
#First - how many studies had a significant trend for each metric? 
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S")) %>% 
  group_by(metric) %>% 
  summarise(n_study_id = n_distinct(study_id)) %>%
  mutate(percent = n_study_id/53) 

#And which studies were they?
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S")) %>% 
  select(study_id, metric) %>%
  distinct()

#Which were significant for multiple metrics?
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S")) %>% 
  group_by(study_id) %>%
  filter(n() > 1) %>%
  select(study_id, metric)
```

#### Analizing slopes
Is slope a function of timeseries characteristics?
```{r}
library(multcomp)

study_slope_data <- study_slopes %>%
  dplyr::select(study_id, metric, estimate) %>%
  left_join(meta %>% 
              dplyr::select(-rarefyid) %>% 
              distinct() %>%
              mutate(study_id = as.character(study_id))) %>%
  left_join(model_data %>% dplyr::select(study_id, startyear, duration) %>% distinct())


duration_slope <- study_slope_data %>%
  group_nest(metric) %>%
  mutate(model = map(data, ~glm(estimate ~ duration, 
                                 data = .x)),
           coef = map(model, tidy),
           ) %>% 
  dplyr::select(metric, coef) %>%
  unnest(cols = c(coef)) %>%
  mutate(covariate = "duration")

startyear_slope <- study_slope_data %>%
  group_nest(metric) %>%
  mutate(model = map(data, ~glm(estimate ~ startyear, 
                                 data = .x)),
           coef = map(model, tidy),
           ) %>% 
  dplyr::select(metric, coef) %>%
  unnest(cols = c(coef)) %>%
  mutate(covariate = "startyear")

#All model estimates in one dataframe
slope_models <- bind_rows(duration_slope, startyear_slope)
pins::pin(slope_models, board = "github")

# Which predictor variables were significant?
slope_models %>% filter(term != "(Intercept)", p.value < 0.05) %>% View()
```
