---
title: "Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lme4)
library(broom.mixed)
library(lmerTest)
library(emmeans)
```
#### Read in data, get final dataset for models
Get data and put it in long form 
```{r}
#get data
load(here::here("data/meta.rda"))
load(here::here("data/bt_traitfiltered.rda"))
load(here::here("data/rarefied_metrics.rda"))

meta <- meta %>%
  select(study_id, realm, climate, habitat, protected_area, biome_map)

meta <- bt_traitfiltered %>% 
  select(study_id, rarefyid, taxa) %>% distinct() %>%
  left_join(meta)

rm(bt_traitfiltered) 

#get metric data
metrics <- rarefied_metrics %>%
  rename_with(tolower, .cols = setdiff(everything(), one_of("rarefyID")))  %>%
  mutate(logvalue = log(value + 1)) %>% # create a column for log transformation that adds the absolute value integer closest to the most negative value to create all positive values
  left_join(meta, c("rarefyID" = "rarefyid"))

## Now the data that actually makes it into the model ##

#get rarefyID's that don't have enough null samples
missing_null <- bind_rows(metrics %>% 
  filter(n_missing_nulls == 1, commplete_null_samps == FALSE),
  metrics %>% filter(n_missing_nulls > 100)) %>%
  pull(rarefyID) %>%
  unique()

model_data <- metrics %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "Jaccard_next",
                       "FRic", "FEve", "FDiv", "S","CWM_bodymass_value","CWM_diet_inv", 
                       "CWM_diet_scav", "CWM_diet_vfish", "CWM_diet_vunk", "CWM_forstrat_ground", 
                       "CWM_forstrat_wataroundsurf", "CWM_forstrat_watbelowsurf", "CWM_diet_fruit", 
                       "CWM_diet_planto", "CWM_diet_seed", "CWM_diet_vend", "CWM_forstrat_understory", 
                       "CWM_diet_vect", "CWM_diet_nect", "CWM_forstrat_aerial", "CWM_forstrat_canopy", 
                       "CWM_forstrat_midhigh", "CWM_age_at_maturity_max_y", "CWM_age_at_maturity_min_y", 
                       "CWM_body_size_mm", "CWM_litter_size_max_n", "CWM_litter_size_min_n", 
                       "CWM_longevity_max_y", "CWM_offspring_size_max_mm", "CWM_offspring_size_min_mm"),
         !rarefyID %in% missing_null) %>%
  group_by(metric) %>%
  mutate(study_id =  str_extract(rarefyID, "[^_]+")) %>%
  mutate(year_scaled = scale(year), 
         scale_center = attributes(year_scaled)$`scaled:center`, 
         scale = attributes(year_scaled)$`scaled:scale`) %>%
  ungroup() %>%
  #this study has many low species richness observations, so FD metrics weren't calculated, just drop it
  filter(study_id != 348) %>%
  #somehow the taxa labels didn't get updated when the timeseries for multi-taxa studies were split up, do that now
   mutate(new_taxa = str_split_fixed(rarefyID, "_", n = 3)[,3],
            taxa = case_when(
            new_taxa == "bird" ~ "Birds",
               new_taxa == "mamm" ~ "Mammals", 
               TRUE ~ as.character(taxa)
           )) %>%
  select(-new_taxa)

usethis::use_data(model_data)
```

Write out file with all necessary metadata for the supplement.
```{r}
meta %>% 
  filter(study_id %in% model_data$study_id) %>% 
  select(-c(link_id, date_study_added, sample_desc_name)) %>% 
  write_csv(here::here("paper", "study_metadata.csv"))
```

####Data exploration

Visualize number of years for each timeseries
```{r}
hist_numYears <- model_data %>%
  select(year, rarefyID) %>% 
  distinct() %>% 
  count(rarefyID, name = "num_years") %>% 
  ggplot() +
  geom_histogram(aes(x = num_years),
                 binwidth = 2) +
  scale_x_continuous(name = 'Number of years sampled',
                     breaks = c(2,4,8,16,32,48,64,96)) +
  #scale_y_continuous(breaks = c(0,2500,5000,7500,10000,12500, 15000, 17500, 20000,22500)) +
  labs(tag = 'B',
       y = 'Number of cells') +
  theme_bw() +
  theme(panel.grid.minor.x = element_blank())

hist_duration <- model_data %>%
  select(rarefyID, duration) %>% 
  distinct() %>% 
  ggplot() +
  geom_histogram(aes(x = duration),
                 binwidth = 2) +
  scale_x_continuous(name = 'Number of years sampled',
                     breaks = c(2,4,8,16,32,48,64,96)) +
  #scale_y_continuous(breaks = c(0,2500,5000,7500,10000,12500, 15000, 17500, 20000,22500)) +
  labs(tag = 'B',
       y = 'Number of cells') +
  theme_bw() +
  theme(panel.grid.minor.x = element_blank())
```

Visualize distributions of response
```{r}
# metrics %>%
#   filter(metric %in% c("FRic", "FEve", "FDiv", "FDis", "S", "Jaccard_hind")) %>%
#   ggplot() +
#   geom_histogram(aes(x = logvalue),
#                  bins = 60) +
#   facet_wrap(~metric, scales = "free") +
#   labs(title = "Distribution of Log values")
# 
# metrics %>%
#   filter(metric %in% c("FRic", "FEve", "FDiv", "FDis", "S", "SES_FDis", "SES_FDiv", "SES_FEve", "SES_FRic", "Jaccard_hind")) %>%
#   ggplot() +
#   geom_histogram(aes(x = value),
#                  bins = 60) +
#   facet_wrap(~metric, scales = "free") +
#   labs(title = "Distribution of raw values")
```

####Fit GLMs to overall patterns and data broken down by groups

Convergence problems! See here:
https://joshua-nugent.github.io/allFit/
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
https://biologyforfun.wordpress.com/2018/04/09/help-i-have-convergence-warnings/

Model checks:
https://debruine.github.io/posts/normality/
performance::check_model()

Function approach to model
```{r}
get_model <- function(metric_name, formula, model_id, data, filter_study_id, ...){
  print(c(metric_name, model_id))
  qlmer <- quietly(lmer)
  print(filter_study_id)
  
  if (missing(filter_study_id)){
    fit_data <- data %>%
      filter(metric == metric_name) %>%
      mutate(year_scaled = scale(year),
             duration_scaled = scale(duration, scale = FALSE),
             startyear_scaled = scale(startyear, scale = FALSE),
             taxa = as.factor(taxa),
             realm = as.factor(realm),
             climate = as.factor(climate))
  } else{
    print("Filter study")
    
    fit_data <- data %>%
      filter(metric == metric_name) %>%
      mutate(year_scaled = scale(year),
             duration_scaled = scale(duration, scale = FALSE),
             startyear_scaled = scale(startyear, scale = FALSE),
             taxa = as.factor(taxa),
             realm = as.factor(realm),
             climate = as.factor(climate)) %>%
      filter(study_id == filter_study_id)
    
    print(n_distinct(fit_data$study_id))
  }
  
  print(dim(fit_data))
  
  # check if there's only one time series
  if(n_distinct(fit_data$rarefyID) < 2){
    return(tibble())
  }
  
  # # check if there are enough time points to fit
  # year_count <- fit_data %>% count(rarefyID)
  # if(any(year_count$n == 1)){
  #   return(tibble())
  # }
  if(!model_id %in% c("base", "base_dur", "base_srt")){
    if(fit_data %>% pull(model_id) %>% n_distinct() >1) {
      
      fit <- qlmer(formula = formula, data = fit_data, ...)
      
      slopes <- get_fixed_slopes(metric = metric_name, model = fit$result, model_id = model_id, model_data = fit_data) 
      
      group_slopes <- as_tibble(slopes$emtrends) %>%
        mutate(effect = "group_slope", group = model_id) %>%
        rename(std.error = SE, estimate = year_scaled.trend, term = model_id)
      
      slope_constrasts <- as_tibble(slopes$contrasts) %>%
        mutate(effect = "contrast", group = model_id) %>%
        rename(std.error = SE, term = contrast, statistic = t.ratio)
      
      df <- tidy(fit$result) %>% 
        bind_rows(group_slopes, slope_constrasts) %>%
        mutate(metric = metric_name, model = list(fit$result), model_id = model_id,
               n_ts = n_distinct(fit_data$rarefyID),
               formula = formula,
               warning = ifelse(length(fit$warnings) == 0, NA, fit$warnings))
    }else{
      return(tibble())
    }
  }else{
    
    fit <- qlmer(formula = formula, data = fit_data, ...)
    
    if (missing(filter_study_id)){
      df_out <- tidy(fit$result) %>%
        mutate(metric = metric_name, model = list(fit$result), model_id = model_id, 
               n_ts = n_distinct(fit_data$rarefyID),
               formula = formula,
               warning = ifelse(length(fit$warnings) == 0, NA, fit$warnings))
    }else
      df_out <- tidy(fit$result) %>%
        mutate(metric = metric_name, model = list(fit$result), model_id = model_id, 
               n_ts = n_distinct(fit_data$rarefyID),
               formula = formula,
               warning = ifelse(length(fit$warnings) == 0, NA, fit$warnings), 
               study_id = filter_study_id)
  }
}

get_fixed_slopes <- function(metric, model, model_id, model_data){
  formula <- paste("pairwise", "~", model_id)
  fit_trends <- emtrends(model, specs = as.formula(formula), var="year_scaled",  mode = "satterth", lmerTest.limit = 20105, data = model_data)
  
  return(fit_trends)
}
#get_model(data = model_data, metric_name = "SES_FRic", "value ~ year_scaled + (year_scaled|study_id/rarefyID) + (year_scaled|climate)", model_id = "base")
```

Function to fit model for studies with only one time series (so a glm)
```{r}
get_glm_model <- function(metric_name, formula, model_id, data, filter_study_id, ...){
  print(c(metric_name, model_id))
  qglm <- quietly(glm)
  print(filter_study_id)
  
  fit_data <- data %>%
    filter(metric == metric_name) %>%
    mutate(year_scaled = scale(year),
           duration_scaled = scale(duration, scale = FALSE),
           startyear_scaled = scale(startyear, scale = FALSE),
           taxa = as.factor(taxa),
           realm = as.factor(realm),
           climate = as.factor(climate)) %>%
    filter(study_id == filter_study_id)
  
  print(n_distinct(fit_data$study_id))
  
  fit <- qglm(formula = formula, data = fit_data, ...)
  
  df_out <- tidy(fit$result) %>%
    mutate(metric = metric_name, model = list(fit$result), model_id = model_id, 
           n_ts = n_distinct(fit_data$rarefyID),
           formula = formula,
           warning = ifelse(length(fit$warnings) == 0, NA, fit$warnings), 
           study_id = filter_study_id)
  
}
```


Create dataframe of mixed effects models to fit
```{r}
metric_names <- unique(model_data$metric)
raw_value_mods <- tibble(metric_name = metric_names[metric_names != "S"], 
                         base = "value ~ year_scaled + (year_scaled|study_id/rarefyID)",
                         taxa = "value ~ year_scaled * taxa + (year_scaled|study_id/rarefyID)",
                         realm = "value ~ year_scaled * realm + (year_scaled|study_id/rarefyID)",
                         climate = "value ~ year_scaled * climate + (year_scaled|study_id/rarefyID)") %>%
  pivot_longer(cols = c(base, taxa, realm, climate), names_to = "model_id", values_to = "formula") %>%
  #don't fit the CWM_litter_size_min_n and climate model, not enough data
  filter(metric_name != "CWM_litter_size_min_n" | model_id != "climate")

log_value_mods <- tibble(metric_name = c("S"), 
                         base = "logvalue ~ year_scaled + (year_scaled|study_id/rarefyID)",
                         taxa = "logvalue ~ year_scaled * taxa + (year_scaled|study_id/rarefyID)",
                         realm = "logvalue ~ year_scaled * realm + (year_scaled|study_id/rarefyID)",
                         climate = "logvalue ~ year_scaled * climate + (year_scaled|study_id/rarefyID)") %>%
  pivot_longer(cols = c(base, taxa, realm, climate), names_to = "model_id", values_to = "formula")

mods <- bind_rows(raw_value_mods, log_value_mods) %>% 
  select(metric_name, formula, model_id)
```

Fit models
```{r}
#exclude amphibians
model_data <- model_data %>% filter(taxa != "Amphibians")

#Fit models with base settings
mod_results <- pmap_dfr(mods, get_model, data = model_data)

#get the models that had convergence warnings
bad_models <- mod_results %>%
  select(metric, model_id, warning) %>% 
  filter(!is.na(warning)) %>% 
  distinct() %>%
  left_join(mods, by = c("metric" = "metric_name", "model_id")) 

#Turn off REML for these models, and they fit! 
bad_mod_results <- pmap_dfr(bad_models %>% select(-warning), get_model, data = model_data, REML = FALSE)

#models that still won't converge
bad_models2 <- bad_mod_results %>%
  select(metric, model_id, warning) %>% 
  filter(!is.na(warning)) %>% 
  distinct() %>%
  left_join(mods, by = c("metric" = "metric_name", "model_id")) 

#Fit with a different algorithm
bad_mod_results2 <- pmap_dfr(bad_models2 %>% select(-warning), get_model, data = model_data, control = lmerControl(optimizer = "bobyqa"))

model_table <- bind_rows(mod_results %>% filter(is.na(warning)), 
          bad_mod_results %>% filter(is.na(warning)),
          bad_mod_results2 %>% filter(is.na(warning))) %>%
  mutate(significant = case_when(
    p.value > 0.05 | lower.CL < 0 & upper.CL > 0 ~ FALSE,
    !is.na(p.value) | !is.na(lower.CL) ~ TRUE,
    TRUE ~ NA
  )) #%>%
  #select(-model)

# get number of observations for each model
# lmm_obs <- model_table %>% 
#   filter(model_id == "base") %>% 
#   select(metric, model) %>% 
#   rowwise() %>% 
#   mutate(nobs = nobs(model)) %>% 
#   select(-model) %>% 
#   distinct()

metric_model_table <- model_table %>% select(-model)

usethis::use_data(metric_model_table)
```

Get list of models that couldn't be fit due to model limitations 
```{r}
#models that were fit
uniq_metric_model <- metric_model_table %>% select(metric, model_id) %>% distinct()
#models we attempted to fit
uniq_mods <- mods %>% select(metric = metric_name, model_id) %>% distinct()

#this is a list of models that weren't fit because there weren't enough timeseries OR they didn't converge
#most are amphibian traits or traits only found for one taxa (with taxa as a covariate), the nectar diet realm model wouldn't converge
missing_mods <- setdiff(uniq_mods, uniq_metric_model)
```

Write out table of model estimates for manuscript
```{r}
#manuscript table
metric_model_table %>% 
  filter(model_id == "base", metric %in% c("S", "Jaccard_base", "SES_FRic", "SES_FEve", "SES_FDiv")) %>% 
  select(-c(model_id, warning, statistic, df)) %>% 
  write_csv(here::here("figures", "man_model_table.csv"))

#supplement of complete model output
metric_model_table %>%
  select(-c(model_id, n_ts, warning, lower.CL, upper.CL, significant)) %>%
  write_csv(here::here("paper", "model_estimates_supp.csv"))
  
```

#### Fit individual models
```{r}
#get list of studies that only have one time series
single_ts <- model_data %>% 
  select(study_id, rarefyID, metric) %>%
  distinct() %>%
  count(study_id, metric) %>%
  filter(n == 1) %>%
  select(-n) %>%
  rename(metric_name = metric, filter_study_id = study_id)

# get dataframe of mixed effects models to fit
metric_df <- bind_rows(tibble(metric_name = metric_names[metric_names != "S"], 
                         formula = "value ~ year_scaled + (year_scaled|rarefyID)"),
          tibble(metric_name = c("S"), 
                         formula = "logvalue ~ year_scaled + (year_scaled|rarefyID)")) %>%
  mutate(model_id = "base")

# exclude studies/metrics with only one rarefyID
mixed_indv_model_df <- map_dfr(unique(model_data$study_id), ~metric_df %>% mutate(filter_study_id = .x)) %>%
  anti_join(single_ts, by = c("metric_name", "filter_study_id"))

# fit models for individual studies 
mixed_indv_mod_results <- pmap_dfr(indv_model_df %>% filter(!metric_name %in% c("Jaccard_base", "Jaccard_next")), get_model, data = model_data)

#get dataframe of glm's to fit
glm_indv_model_df <- single_ts %>% 
  mutate(model_id = "base",
         formula = "value ~ year_scaled")

#fit them
glm_indv_mod_results <- pmap_dfr(glm_indv_model_df, get_glm_model, data = model_data)

indv_mod_results <- bind_rows(mixed_indv_mod_results, glm_indv_mod_results)
```


#### Process Model Output

Get study level slope estimates
```{r}
get_study_slopes <- function(metric, model, model_id){
  
  filter_name <- ifelse(model_id == "base", "study_id", model_id)
  
  #get the statistics for the year variable
  year_scaled_coef <- tidy(model) %>%
    filter(term == "year_scaled") 
  
  #get the year estimate
  year_scaled_est <- pull(year_scaled_coef, estimate) 
  
  #get year variation
  year_scaled_var <- year_scaled_coef %>% 
    mutate(var = std.error*std.error) %>%
    pull(var)
  
  #get study level conditional estimates and add to over all estimates
  study_ests <- broom.mixed::tidy(model, effects="ran_vals") %>%
    filter(group == filter_name, term == "year_scaled") %>% 
    select(-c(effect, group, term)) %>%
    rename(cond.std.error = std.error, cond.estimate = estimate) %>%
    mutate(estimate = cond.estimate + year_scaled_est,
      cond.var = cond.std.error*cond.std.error, 
           var = cond.var + year_scaled_var,
           std.error = sqrt(var),
           upr.ci = estimate + (1.96*std.error),
           lwr.ci = estimate - (1.96*std.error),
           sig = case_when(
             lwr.ci < 0 & upr.ci > 0 ~ FALSE,
             TRUE ~ TRUE
           ),
      metric = metric,
      model_id = model_id)
}

model_df <- model_table %>%
  filter(model_id == "base") %>%
  select(metric, model, model_id) %>%
  group_by(metric, model_id) %>% 
  slice_head()

#get study level slopes for base, and levels for categorical random effect in non-base models
re_slopes <- pmap_dfr(model_df, get_study_slopes)

#get only study-level slopes for the base models
study_slopes <- re_slopes %>% 
  filter(model_id == "base") %>%
  rename(study_id = level)

usethis::use_data(study_slopes)
```

Get study level slopes using bootstrap resampling
```{r}
extract_study_slopes <- function(model){
  
  #get the statistics for the year variable
  year_scaled_est <- tidy(model) %>%
    filter(term == "year_scaled") %>%
    pull(estimate)
  
  estimate <- broom.mixed::tidy(model, effects="ran_vals") %>%
    filter(group == "study_id", term == "year_scaled") %>% 
    select(-c(effect, group, term)) %>%
    rename(cond.estimate = estimate) %>%
    mutate(estimate = cond.estimate + year_scaled_est) %>%
    select(level, estimate) %>%
    deframe()
  
  return(estimate)
}

bootstrap_study_slopes <- function(metric, model, model_id, nsim){
  print(c(metric, model_id))
  
  fric_vars <- bootMer(model, FUN = extract_study_slopes, nsim = nsim, use.u = TRUE)
  
  estimates <- enframe(fric_vars$t0, name = "study_id", value = "estimate") 
  
  as_tibble(fric_vars$t) %>% 
    pivot_longer(everything(), names_to = "study_id", values_to = "values") %>%
    group_by(study_id) %>%
    summarize(n = n(), std.error = sd(values)/sqrt(n)) %>%
    left_join(estimates) %>%
    select(-n) %>%
    mutate(metric = metric, model_id = model_id)
}

#future::plan("multisession", workers = 30)

bootstrap_slopes <- pmap_dfr(model_df %>% filter(model_id == "base") %>% mutate(nsim = 100), bootstrap_study_slopes) %>%
  # furrr::future_pmap_dfr(model_df %>% filter(model_id == "base") %>% mutate(nsim = 100), bootstrap_study_slopes, 
  #                                          .options = furrr::furrr_options(seed = TRUE)) %>%
  mutate(upr.ci = estimate + (2*std.error),
         lwr.ci = estimate - (2*std.error),
         sig = case_when(
             lwr.ci < 0 & upr.ci > 0 ~ FALSE,
             TRUE ~ TRUE
           ))

slope_comp <- study_slopes %>% 
  select(study_id, metric, sig_bulp = sig) %>%
  left_join(bootstrap_slopes %>% 
              select(study_id, metric, sig_boot = sig)) %>%
  left_join(indv_mod_results %>%
              filter(term == "year_scaled") %>%
            mutate(sig_indv = if_else(p.value < 0.05, TRUE, FALSE)) %>%
              select(study_id, metric, sig_indv))
```

Summaries of study slopes
```{r}
#First - how many studies had a significant trend for each metric? 
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S")) %>% 
  mutate(positive = ifelse(estimate > 0, TRUE, FALSE)) %>%
  group_by(metric, positive) %>% 
  summarise(n_study_id = n_distinct(study_id)) 

#And which studies were they?
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S", "FRic", "FEve", "FDiv")) %>% 
  select(study_id, metric) %>%
  distinct()

#Which were significant for multiple metrics?
study_slopes %>% 
  filter(sig == TRUE) %>% 
  filter(metric %in% c("SES_FRic", "SES_FEve", "SES_FDiv", "Jaccard_base", "S")) %>% 
  group_by(study_id) %>%
  filter(n() > 1) %>%
  select(study_id, metric)
```

#### Analizing slopes
Is slope a function of time series characteristics?
```{r}
library(multcomp)

study_slope_data <- study_slopes %>%
  dplyr::select(study_id, metric, estimate) %>%
  left_join(meta %>% 
              mutate(study_id = as.character(study_id))) %>%
  left_join(model_data %>% dplyr::select(study_id, startyear, duration) %>% distinct())


duration_slope <- study_slope_data %>%
  group_nest(metric) %>%
  mutate(model = map(data, ~glm(estimate ~ duration, 
                                 data = .x)),
           coef = map(model, tidy),
           ) %>% 
  dplyr::select(metric, coef) %>%
  unnest(cols = c(coef)) %>%
  mutate(covariate = "duration")

startyear_slope <- study_slope_data %>%
  group_nest(metric) %>%
  mutate(model = map(data, ~glm(estimate ~ startyear, 
                                 data = .x)),
           coef = map(model, tidy),
           ) %>% 
  dplyr::select(metric, coef) %>%
  unnest(cols = c(coef)) %>%
  mutate(covariate = "startyear")

#All model estimates in one dataframe
# slope_models <- bind_rows(duration_slope, startyear_slope)

# Which predictor variables were significant?
slope_models %>% filter(term != "(Intercept)", p.value < 0.05) %>% View()
```

#### Looking at BBS specifically to compare slopes and significance
```{r}
bbs_models <- map_dfr(metric_names[metric_names != "S"], 
                      ~get_model(data = model_data, 
                                 metric_name = .x, "value ~ year_scaled + (year_scaled|rarefyID)", 
                                 model_id = "base",
                                 study_id = 195))

bbs_models %>% 
  filter(term == "year_scaled") %>% 
  rowwise() %>% 
  mutate(nobs = nobs(model)) %>% 
  select(-model, -model_id, -formula, -n_ts, -warning, -group) %>% 
  relocate(metric) %>% 
  arrange(metric) %>% 
  write_csv(here::here("data/bbs_slopes_indvmodels.csv"))
```

